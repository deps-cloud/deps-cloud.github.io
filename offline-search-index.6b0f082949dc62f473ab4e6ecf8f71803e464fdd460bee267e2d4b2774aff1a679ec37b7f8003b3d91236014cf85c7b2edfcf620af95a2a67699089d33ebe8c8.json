[{"body":"Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nOur Standards Examples of behavior that contributes to creating a positive environment include:\n Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members  Examples of unacceptable behavior by participants include:\n The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others\u0026rsquo; private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting  Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\nScope This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\nEnforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project owner on Gitter. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project\u0026rsquo;s leadership.\nAttribution This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\nFor answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq\n","excerpt":"Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and …","ref":"/docs/contrib/code-of-conduct/","title":"Code of Conduct"},{"body":"","excerpt":"","ref":"/docs/concepts/","title":"Concepts"},{"body":"Many concepts from the deps.cloud ecosystem stem from graph theory.\nGraphs are a data structure used to model relationships between objects. They consist of nodes (entities) and edges (associations). Edges in a graph can be directed or undirected. Graphs can be acyclic, meaning they contain no cycles.\nDependency graphs are directed graphs that represent dependencies between objects. This data structure is at the heart of deps.cloud. To best explain, let us consider a simple example.\n A depends on B B depends on D B depends on C C depends on D  Conceptually, this looks something like the following.\nEven with our simple example, we can start to see the complexity that comes with a dependency graph. Since edges often reference data between nodes of the same type, mapping concepts to traditional solutions can be difficult.\nGraph traversal Graph traversal refers to the process of walking and navigating a graph. They are similar to tree traversals, but require tracking nodes you\u0026rsquo;ve visited as it\u0026rsquo;s possible to encounter cycles. To simplify this for consumers, deps.cloud provides a search API for traversing it\u0026rsquo;s graph.\nBreadth-first Search Breadth-first search (commonly abbreviated BFS) is an algorithm used to traverse tree and graph data structures. This approach often starts with a root node. The algorithm progresses by visiting neighbors of increasing depth, level by level.\nDepth-first Search Depth-first search (commonly abbreviated DFS) is another traversal algorithm. In this traversal, branches of the data structure are exhausted before backtracking. Unlike BFS, there are several possible orderings for the output of a DFS:\n A preordering lists all nodes in the order they were first visit. A postordering lists all nodes in the order they were last visited. A reverse preordering lists all nodes in the opposite order they were first visit. This is not the same as a postordering. A reverse postordering lists all nodes in the opposite order they were last visited. This is not the same as a preordering.  Next Steps To learn more about how information is stored, head over to the data model documentation.\nTo learn about how information is extracted, head over to the manifest file documentation.\n","excerpt":"Many concepts from the deps.cloud ecosystem stem from graph theory.\nGraphs are a data structure used …","ref":"/docs/concepts/graphs/","title":"Dependency Graphs"},{"body":"In this quick start guide, we\u0026rsquo;ll use docker-compose to create our demo infrastructure.\nTo get started quickly, you should clone the deploy repository and leverage the configuration under the docker directory. You can pick any storage solution you\u0026rsquo;d like, but this guide follows the configuration in sqlite.\n1 - Launch deps.cloud To launch the demo infrastructure, simply run the following:\n$ docker-compose up -d Creating docker_extractor_1 ... done Creating docker_tracker_1 ... done Creating docker_indexer_1 ... done Creating docker_gateway_1 ... done That\u0026rsquo;s it!\nThe deps.cloud demo infrastructure is up and running. You can test it out by opening any of the following endpoints (browser or curl).\n What sources have been indexed? What modules are produced by this repository? What modules do I depend on and what version? What modules depend on me and what version? What repositories can produce this module?  2 - Configure Your Provider Once the demo infrastructure is up and running, you can easily modify the rds.yaml file to include more accounts to index. For more information on how to configure each integration, see the integrations section. For now, let\u0026rsquo;s simply add your GitHub ID to the existing block.\naccounts: - github: strategy: HTTP users: - { .GitHubLogin } organizations: - depscloud The configuration will not be automatically reloaded. Any process consuming the configuration will need to be restarted.\n3 - Rerun Indexer The indexer process is typically run as a cronjob. Because of this, it will typically pick up the configuration on it\u0026rsquo;s next run. When running locally, we can restart the process to pick up the new configuration. You may need to re-create the container.\n$ docker-compose restart indexer Restarting docker_indexer_1 ... done ","excerpt":"In this quick start guide, we\u0026rsquo;ll use docker-compose to create our demo infrastructure.\nTo get …","ref":"/docs/deploy/docker/","title":"Docker"},{"body":"GitHub is the largest source of repositories. Most companies have an account where they maintain their code repositories. Due to the system\u0026rsquo;s popularity, it was one of the first integrations that was targeted. Below, you\u0026rsquo;ll find the full set of configuration options that can be specified for a GitHub account.\naccounts:# full github schema- github:base_url:\u0026#34;\u0026lt;base_url\u0026gt;\u0026#34;upload_url:\u0026#34;\u0026lt;base_url\u0026gt;\u0026#34;users:- \u0026#34;\u0026lt;username\u0026gt;\u0026#34;organizations:- \u0026#34;\u0026lt;organization\u0026gt;\u0026#34;strategy:\u0026#34;SSH | HTTP\u0026#34;oauth2:token:\u0026#34;\u0026lt;oauth_token\u0026gt;\u0026#34;token_type:\u0026#34;\u0026lt;token_type\u0026gt;\u0026#34;refresh_token:\u0026#34;\u0026lt;refresh_token\u0026gt;\u0026#34;expiry:\u0026#34;\u0026lt;expiry\u0026gt;\u0026#34;Due to the variance in each of the client, there are a few oddities between each of the implementations. While we work on getting parity between each of the providers take note that this implementation:\n does not pull groups for the authenticated user pull groups for the configured users pulls repositories for all users and groups (configured and discovered)  Example Crawl all of Google\u0026rsquo;s public repositories on GitHub.\naccounts:- github:organizations:- googlestrategy:HTTP","excerpt":"GitHub is the largest source of repositories. Most companies have an account where they maintain …","ref":"/docs/deploy/config/indexing/github/","title":"GitHub"},{"body":" Storage Driver: sqlite Read-Write Connection String: file:depscloud.db?cache=shared\u0026amp;mode=rwc Read-Only Connection String: file:depscloud.db?cache=shared\u0026amp;mode=ro  Docker If using the simple Docker set up, these values can be configured using the --storage-driver, --storage-address, and --storage-readonly-address command line arguments.\nKubernetes With Kubernetes, you\u0026rsquo;ll need to configure the secret object manually. The block below demonstrates how to set up the depscloud-tracker configuration for SQLite.\napiVersion:v1kind:Secretmetadata:name:depscloud-trackerstringData:STORAGE_DRIVER:sqliteSTORAGE_ADDRESS:file:depscloud.db?cache=shared\u0026amp;mode=rwcSTORAGE_READ_ONLY_ADDRESS:file:depscloud.db?cache=shared\u0026amp;mode=roHelm With the Helm chart, you have two options. First, you can pass the values into the helm chart as arguments during installation.\n$ helm upgrade -i depscloud depscloud/depscloud \\  --set tracker.storage.driver=sqlite \\  --set \u0026#34;tracker.storage.address=file:depscloud.db?cache=shared\u0026amp;mode=rwc\u0026#34; \\  --set \u0026#34;tracker.storage.readOnlyAddress=file:depscloud.db?cache=shared\u0026amp;mode=ro\u0026#34; Or, you can pass a reference to a secret as described in the previous Kubernetes section.\n$ helm upgrade -i depscloud depscloud/depscloud \\  --set tracker.externalStorage.secretRef.name=depscloud-tracker ","excerpt":"Storage Driver: sqlite Read-Write Connection String: file:depscloud.db?cache=shared\u0026amp;mode=rwc …","ref":"/docs/deploy/config/storage/sqlite/","title":"SQLite"},{"body":"deps.cloud was built with portability in mind. As a result, we wanted to support common relational database systems that we could expect at other companies. While not officially supported, you could replace the specific technology with a protocol compatible equivalent. For example, you might replace MySQL with MariaDB or Vitess. Or PostgreSQL with something like CockroachDB.\n SQLite     MySQL     PostgreSQL     ","excerpt":"deps.cloud was built with portability in mind. As a result, we wanted to support common relational …","ref":"/docs/deploy/config/storage/","title":"Storage"},{"body":"Online The team has used several communication tools. Like most projects, we wound up on Slack. If you have trouble joining, please do not hesitate to reach out to the mailing list for additional support.\nMeetings Until further notice community meetings have been paused. If large enough interest has been expressed, we can start them back up again.\n ","excerpt":"Online The team has used several communication tools. Like most projects, we wound up on Slack. If …","ref":"/docs/contrib/community/","title":"Community"},{"body":"The backing data model for deps.cloud is a graph. Graphs contain two types of data: nodes and edges. Nodes often represent entities such as people, places, or things. Edges often represent relationships between two entities.\nOverview The following illustrates the various nodes and edges in the deps.cloud ecosystem.\nNodes Sources represent origins for information. These can be source control systems like GitHub, GitLab, or BitBucket. Or they can be artifactories like JFrog Artifactory or Sonatype Nexus. Sources are keyed by their URL and are represented as nodes in the dependency graph.\nModules represent libraries or applications in the dependency graph. These are the components extracted from manifest files. They are keyed by all their data, and are represented as nodes in the dependency graph.\nEdges Manages represent the relationship between a source and a module. It contains information about how a given module is managed such as the toolchain.\nDepends represents the relationship between two modules. It contains information about how the modules depend on one another. This includes things like version constraint, scopes, and a reference to the source.\nNext Steps To learn about how information is extracted, head over to the manifest file documentation.\nTo learn more about how the system is deployed, head over to the architecture documentation.\n","excerpt":"The backing data model for deps.cloud is a graph. Graphs contain two types of data: nodes and edges. …","ref":"/docs/concepts/data-model/","title":"Data Model"},{"body":"The deployment of deps.cloud is easy. While there may still be some rough edges, the intent was to make it possible for any company to drop it into place. The sections below provide you with details around the various deployment options.\n Docker     Kubernetes     Helm     Configuration  Storage     Indexing     ","excerpt":"The deployment of deps.cloud is easy. While there may still be some rough edges, the intent was to …","ref":"/docs/deploy/","title":"Deployment"},{"body":"GitLab is a common provider used by those seeking an on-premise solution who do not want their source code managed by a third party provider. Many companies choose to run this system internally. Below, you will find the list of options that can be configured to get the system running. Either private or oauth should be provided. Otherwise, you will only have access to public repositories. I\u0026rsquo;ve found configuring the private token to be the easiest.\naccounts:# full gitlab schema- gitlab:base_url:\u0026#34;\u0026lt;base_url\u0026gt;\u0026#34;users:- \u0026#34;\u0026lt;username\u0026gt;\u0026#34;groups:- \u0026#34;\u0026lt;groupname\u0026gt;\u0026#34;strategy:\u0026#34;SSH | HTTP\u0026#34;private:token:\u0026#34;\u0026lt;private_token\u0026gt;\u0026#34;oauth:token:\u0026#34;\u0026lt;oauth_token\u0026gt;\u0026#34;application_id:\u0026#34;\u0026lt;application_id\u0026gt;\u0026#34;Due to the variance in each of the client, there are a few oddities between each of the implementations. While we work on getting parity between each of the providers take note that this implementation:\n pulls groups for the authenticated user does not pull groups for the configured users pulls repositories for all users and groups (configured and discovered)  Example Crawl all of Nvidia\u0026rsquo;s public repositories on GitLab.\naccounts:- gitlab:groups:- nvidiastrategy:HTTP","excerpt":"GitLab is a common provider used by those seeking an on-premise solution who do not want their …","ref":"/docs/deploy/config/indexing/gitlab/","title":"GitLab"},{"body":"This section provides guidance on how to configure the underlying system. Keep in mind, how you update the configuration depends on your deployment strategy. If you\u0026rsquo;re using Docker, you will be changing the config.yaml file. If you\u0026rsquo;re using Kubernetes, you will need to change the config.yaml key in the depscloud-indexer Secret.\n GitHub     GitLab     BitBucket     ","excerpt":"This section provides guidance on how to configure the underlying system. Keep in mind, how you …","ref":"/docs/deploy/config/indexing/","title":"Indexing"},{"body":"This guide explains how to run the deps.cloud infrastructure within a Kubernetes cluster.\nPrerequisites  A working Kubernetes cluster. To follow along with this guide, you should set up minikube on your machine. Minikube provides a great way to test and experiment around with Kubernetes locally. The kubectl binary should be installed and in your path on your workstation.  1 - Configure a Storage Class deps.cloud leverages MySQL to store a given graphs dependency information. MySQL requires a persistent volume to be able to ensure the data is persisted to disk. In Kubernetes, a Persistent Volume can either be manually provisioned by a System Administrator or Dynamically provisioned using a Storage Class. To figure out if you need to install a Storage Class, you can use kubectl to see which ones have been configured on the cluster already.\n$ kubectl get storageclasses.storage.k8s.io NAME PROVISIONER AGE standard (default) k8s.io/minikube-hostpath 14d If you\u0026rsquo;re have none, you can configure a local-storage class. This leverages the storage provided by the host that the pod is running on. It also creates an affinity so that the next time the pod restarts, it will prefer that host over the others.\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: local-storage provisioner: kubernetes.io/no-provisioner volumeBindingMode: WaitForFirstConsumer EOF 2 - Set-up Workspace Before deploying any workloads, we first need a workspace to deploy into. The following command creates a Kubernetes namespace with the name depscloud.\n$ kubectl create ns depscloud Once created, Network Policies, Resource Quotas, and RBAC can be used to lock down the system. All the resources created in this walk through will be deployed to this namespace.\n3 - Deploy MySQL If you don\u0026rsquo;t already have a MySQL database available, you can deploy one using one of the many helm charts out there. The following deployment was generated from the bitnami/mysql.\n$ kubectl apply -n depscloud -f https://depscloud.github.io/deploy/k8s/mysql.yaml This deployment comes with a single primary node and a read only replica node.\n4 - Configure deps.cloud By default, the tracker and indexer do not come configured. This allows operators to connect it to provide their specific configuration. To configure these processes, you\u0026rsquo;ll need to create two secrets in the depscloud namespace.\nTo configure the tracker, you\u0026rsquo;ll need to provide a depscloud-tracker secret. This secret is used to connect the tracker to the previously provisioned MySQL database.\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: Secret metadata: namespace: depscloud name: depscloud-tracker stringData: STORAGE_DRIVER: mysql STORAGE_ADDRESS: user-rw:password@tcp(mysql:3306)/depscloud STORAGE_READ_ONLY_ADDRESS: user:password@tcp(mysql:3306)/depscloud EOF To configure the indexer, you\u0026rsquo;ll need to provide a depscloud-indexer secret. This file tells the indexer how to discovery and clone repositories. The following configuration will index the deps.cloud repositories.\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: Secret metadata: namespace: depscloud name: depscloud-indexer stringData: config.yaml: | accounts: - github: strategy: HTTP organizations: - depscloud EOF You can learn more about how to configure the indexer process on the integrations page.\n4 - Deploy deps.cloud After the tracker and indexer have been configured, you\u0026rsquo;ll be able to deploy the deps.cloud infrastructure. This configuration can be found with the other deployment configuration on GitHub.\n$ kubectl apply -n depscloud -f https://depscloud.github.io/deploy/k8s/depscloud-system.yaml Once all processes have completed and are healthy, you should be able to interact with the API pretty easily. To quickly test this, you can port forward to one of the gateway pods directly.\n$ kubectl port-forward -n depscloud svc/depscloud-gateway 8080:80 Forwarding from 127.0.0.1:8080 -\u0026gt; 8080 Forwarding from [::1]:8080 -\u0026gt; 8080 Once the port is forwarded, the following endpoints should be able to be reached.\n What sources have been indexed? What modules are produced by this repository? What modules do I depend on and what version? What modules depend on me and what version? What repositories can produce this module?  ","excerpt":"This guide explains how to run the deps.cloud infrastructure within a Kubernetes cluster. …","ref":"/docs/deploy/k8s/","title":"Kubernetes"},{"body":" Driver: mysql Read-Write Connection String: user-rw:password@tcp(depscloud-mysql:3306)/depscloud Read-Only Connection String: user:password@tcp(depscloud-mysql:3306)/depscloud  Docker If using the simple Docker set up, these values can be configured using the --storage-driver, --storage-address, and --storage-readonly-address command line arguments.\nKubernetes With Kubernetes, you\u0026rsquo;ll need to configure the secret object manually. The block below demonstrates how to set up the depscloud-tracker configuration for MySQL.\napiVersion:v1kind:Secretmetadata:name:depscloud-trackerstringData:STORAGE_DRIVER:mysqlSTORAGE_ADDRESS:user-rw:password@tcp(depscloud-mysql:3306)/depscloudSTORAGE_READ_ONLY_ADDRESS:user:password@tcp(depscloud-mysql:3306)/depscloudHelm With the Helm chart, you have two options. First, you can pass the values into the helm chart as arguments during installation.\n$ helm upgrade -i depscloud depscloud/depscloud \\  --set tracker.storage.driver=mysql \\  --set \u0026#34;tracker.storage.address=user-rw:password@tcp(depscloud-mysql:3306)/depscloud\u0026#34; \\  --set \u0026#34;tracker.storage.readOnlyAddress=user:password@tcp(depscloud-mysql:3306)/depscloud\u0026#34; Or, you can pass a reference to a secret as described in the previous Kubernetes section.\n$ helm upgrade -i depscloud depscloud/depscloud \\  --set tracker.externalStorage.secretRef.name=depscloud-tracker Using MariaDB Compatibility with MariaDB has not yet been tested. Since MariaDB claims to be MySQL compatible, there shouldn\u0026rsquo;t be any issues. Contributions are welcome!\nUsing Vitess Compatibility with Vitess has not yet been tested. Since Vitess claims to be MySQL compatible, there shouldn\u0026rsquo;t be any issues. Contributions are welcome!\n","excerpt":"Driver: mysql Read-Write Connection String: user-rw:password@tcp(depscloud-mysql:3306)/depscloud …","ref":"/docs/deploy/config/storage/mysql/","title":"MySQL"},{"body":"BitBucket is a common provider used by those seeking private repository support with great integration into existing Atlassian products (like Jira and Confluence). Below is the complete set of options that can be used to configure your integration. Either basic or oauth should be provided. Otherwise, you will only have access to public repositories. I\u0026rsquo;ve found that basic using an application password has been the easiest to configure.\naccounts:# full bitbucket schema- bitbucket:users:- \u0026#34;\u0026lt;username\u0026gt;\u0026#34;teams:- \u0026#34;\u0026lt;teamname\u0026gt;\u0026#34;strategy:\u0026#34;SSH | HTTP\u0026#34;basic:username:\u0026#34;\u0026lt;username\u0026gt;\u0026#34;password:\u0026#34;\u0026lt;app_password\u0026gt;\u0026#34;oauth:token:\u0026#34;\u0026lt;oauth_token\u0026gt;\u0026#34;application_id:\u0026#34;\u0026lt;application_id\u0026gt;\u0026#34;Due to the variance in each of the client, there are a few oddities between each of the implementations. While we work on getting parity between each of the providers take note that this implementation:\n does not pull groups for the authenticated user does not pull groups for the configured users pulls repositories for all configured users and groups  Example Crawl all of Atlassian\u0026rsquo;s public repositories on BitBucket.\naccounts:- bitbucket:teams:- atlassianstrategy:HTTP","excerpt":"BitBucket is a common provider used by those seeking private repository support with great …","ref":"/docs/deploy/config/indexing/bitbucket/","title":"Bitbucket"},{"body":"This guide explains how to run the deps.cloud infrastructure within a Kubernetes cluster using the Helm package manager.\nPrerequisites  A working Kubernetes cluster. To follow along with this guide, you should set up minikube on your machine. Minikube provides a great way to test and experiment around with Kubernetes locally. The kubectl binary should be installed and in your path on your workstation. The helm binary should be installed and in your path on your workstation.  1 - Adding the Helm Repository In order to leverage the deps.cloud Helm charts, you first need to add the deps.cloud stable repository.\n$ helm repo add depscloud https://depscloud.github.io/deploy/charts \u0026quot;depscloud\u0026quot; has been added to your repositories $ helm repo update 2 - Deploy the deps.cloud Infrastructure Once the deps.cloud chart repository has been added, you can install the charts as follows.\n$ kubectl create ns depscloud namespace/depscloud created $ helm upgrade -n depscloud -i depscloud depscloud/depscloud Release \u0026quot;depscloud\u0026quot; does not exist. Installing it now. NAME: depscloud LAST DEPLOYED: Sat Jun 20 16:50:57 2020 NAMESPACE: depscloud STATUS: deployed REVISION: 1 TEST SUITE: None This same command can be used to upgrade the system in the future.\n3 - Querying the deps.cloud Infrastructure Once all processes have completed and are healthy, you should be able to interact with the API pretty easily. Note that there will be no data in the API until the indexer process has run. To quickly test this, you can port forward the depscloud-gateway service.\n$ kubectl port-forward -n depscloud svc/depscloud-gateway 8080:80 Forwarding from 127.0.0.1:8080 -\u0026gt; 8080 Forwarding from [::1]:8080 -\u0026gt; 8080 Once the port is forwarded, the following endpoints should be able to be reached.\n What sources have been indexed? What modules are produced by this repository? What modules do I depend on and what version? What modules depend on me and what version? What repositories can produce this module?  4 - Configuring using values.yaml A values.yaml file can be used to maintain deployment specific configuration. The content below provides an example of how to configure the indexer to crawl the depscloud account.\n# contents of values.yamlindexer:config:accounts:- github:clone:strategy:HTTPorganizations:- depscloudtracker:storage:driver:sqlite|mysql|postgresaddress:\u0026#34;\u0026#34;readOnlyAddress:\u0026#34;\u0026#34;Then during install, you can pass in the values.yaml file.\n$ helm upgrade -n depscloud -i depscloud depscloud/depscloud -f values.yaml 5 - Optional Installments The following are optional considerations. You do not need to install them to run the system, but can make managing it easier.\nIngress By using an ingress address and controller, you can easily expose the REST API.\napiVersion:networking.k8s.io/v1beta1kind:Ingressmetadata:namespace:depscloudname:depscloudspec:rules:- host:depscloud.internal.company.nethttp:paths:- path:/backend:serviceName:depscloud-gatewayservicePort:80Using helm-operator The helm-operator provided by fluxcd is an extremely powerful resource. If provides a way to manage Helm releases within a cluster through custom resource definitions.\napiVersion:helm.fluxcd.io/v1kind:HelmReleasemetadata:namespace:depscloudname:depscloudspec:releaseName:depscloudchart:repository:https://depscloud.github.io/deploy/chartsname:depscloudvalues:indexer:schedule:\u0026#34;@daily\u0026#34;config:accounts:- github:clone:strategy:HTTPorganizations:- depscloud","excerpt":"This guide explains how to run the deps.cloud infrastructure within a Kubernetes cluster using the …","ref":"/docs/deploy/helm/","title":"Helm"},{"body":"A manifest is the generic term used to describe documents that communicate a systems requirements or dependencies. These dependencies come in many shapes and forms, but the most common dependency is a library. Libraries are packages containing common code that is shared between projects.\nUsing this information, deps.cloud is able to build a knowledge graph. The table below demonstrates how to interpret the information extracted from various manifests. Since there is no standardization across languages, extraction may vary between implementations.\n   Manifest File Example Language System Organization Module     bower.json @depscloud/api node bower depscloud api   build.gradle com.google.guava:guava java gradle com.google.guava guava   cargo.toml bytes rust cargo _ bytes   composer.json symfony/console php composer symfony console   Godeps.json github.com/depscloud/api go godeps github.com depscloud/api   go.mod github.com/depscloud/api go vgo github.com depscloud/api   Gopkg.toml github.com/depscloud/api go gopkg github.com depscloud/api   ivy.xml com.google.guava;guava java ivy com.google.guava guava   package.json @depscloud/api node npm depscloud api   pom.xml com.google.guava;guava java maven com.google.guava guava   vendor.conf github.com/depscloud/api go vendor github.com depscloud/api    Next Steps To learn more about how information is stored, head over to the data model documentation.\nTo learn more about how the system is deployed, head over to the architecture documentation.\n","excerpt":"A manifest is the generic term used to describe documents that communicate a systems requirements or …","ref":"/docs/concepts/manifests/","title":"Manifest Files"},{"body":" Driver: postgres Read-Write Connection String: postgres://user-rw:password@depscloud-postgresql:5432/depscloud Read-Only Connection String: postgres://user:password@depscloud-postgresql:5432/depscloud  Docker If using the simple Docker set up, these values can be configured using the --storage-driver, --storage-address, and --storage-readonly-address command line arguments.\nKubernetes With Kubernetes, you\u0026rsquo;ll need to configure the secret object manually. The block below demonstrates how to set up the depscloud-tracker configuration for PostgreSQL.\napiVersion:v1kind:Secretmetadata:name:depscloud-trackerstringData:STORAGE_DRIVER:postrgresSTORAGE_ADDRESS:postgres://user-rw:password@depscloud-postgresql:5432/depscloudSTORAGE_READ_ONLY_ADDRESS:postgres://user:password@depscloud-postgresql:5432/depscloudHelm With the Helm chart, you have two options. First, you can pass the values into the helm chart as arguments during installation.\n$ helm upgrade -i depscloud depscloud/depscloud \\  --set tracker.storage.driver=postrgres \\  --set \u0026#34;tracker.storage.address=postgres://user-rw:password@depscloud-postgresql:5432/depscloud\u0026#34; \\  --set \u0026#34;tracker.storage.readOnlyAddress=postgres://user:password@depscloud-postgresql:5432/depscloud\u0026#34; Or, you can pass a reference to a secret as described in the previous Kubernetes section.\n$ helm upgrade -i depscloud depscloud/depscloud \\  --set tracker.externalStorage.secretRef.name=depscloud-tracker Using CockroachDB Compatibility with CockroachDB has not yet been tested. Since CockroachBD claims to be PostgreSQL compatible, there shouldn\u0026rsquo;t be any issues. Contributions are welcome!\n","excerpt":"Driver: postgres Read-Write Connection String: …","ref":"/docs/deploy/config/storage/postgres/","title":"PostgreSQL"},{"body":"","excerpt":"","ref":"/docs/guides/","title":"User Guides"},{"body":"Cloning Projects Once you\u0026rsquo;ve forked the repository, you\u0026rsquo;ll want to clone it locally for development. For convenience, I tend to work out of the GOPATH directory. Using the following command, you can quickly build a directory for all the depscloud related work.\n$ mkdir -p ${GOPATH}/src/github.com/depscloud \u0026amp;\u0026amp; cd $_ Once you have a workspace, clone the upstream project. This will allow you to regularly pull updates from the origin.\n$ git clone git@github.com:depscloud/\u0026lt;project\u0026gt;.git Building and Running Projects There are two ways you can build and run this project. First you can develop using docker (the recommended way). Each repository ships with two dockerfiles, one for building and testing locally, another for publishing. The second way to build and run this project. This mechanism is not recommended, but can often help quickly testing things without the overhead of docker.\n Developing in Docker (Recommended)  Branching The most common way you will likely create a branch is through the use of a GitHub issue within the repository. To create a branch for GitHub issue #11, simply create a branch with the name gh-11.\n$ git checkout -b gh-11 In some rare occasions you might be working on a issue that requires work across multiple repositories. In this case, you should used the deps.cloud repository to create a parent issue that the other issues can reference and link to. To link another projects issue, you can use the \u0026lt;user\u0026gt;/\u0026lt;project\u0026gt;#11 semantic. Similarly, you can create a feature branch using the same syntax.\n$ git checkout -b \u0026lt;user\u0026gt;/\u0026lt;project\u0026gt;#11 Forking and Submitting Pull Requests By and large, forks are used to submit pull requests to the upstream repositories.\nAfter a project has been cloned, you will need to add your fork as a remote.\n$ git remote add \u0026lt;myuser\u0026gt; git@github.com:\u0026lt;myuser\u0026gt;/\u0026lt;project\u0026gt;.git By doing this, you\u0026rsquo;re able to maintain two references: one for upstream updates and one for your set of changes. When pushing a branch to, you can specify the -u option to have your local branch track a specific remote.\n$ git push -u \u0026lt;myuser\u0026gt; gh-11 From here, all git push operations will default to using your fork. After a branch has been pushed, you can use pull requests to have your code reviewed by the team.\n","excerpt":"Cloning Projects Once you\u0026rsquo;ve forked the repository, you\u0026rsquo;ll want to clone it locally for …","ref":"/docs/contrib/git/","title":"Working with Git"},{"body":"The following diagram illustrates the general system deployed on top of a kubernetes cluster.\nActors User CLI represents a single type of consumer. The command line interface (CLI) allows individuals to explore data stored in deps.cloud. Other types of clients include processes written using one of our SDKs.\nGateway is the face of the API services. It provides both RESTful and gRPC interfaces to clients of the system. Not all functionality is available over the RESTful interface.\nTracker provides several APIs for navigating the graph. This service leverages systems like as SQLite, MySQL, or PostgreSQL to store the graph data.\nExtractor extracts dependency information from manifest files. This mechanism is easily pluggable to support a large range of manifest files.\nThe indexer crawls repositories looking for manifest files. When it discovers manifests, the contents are extracted, stored, and indexed.\n","excerpt":"The following diagram illustrates the general system deployed on top of a kubernetes cluster.\nActors …","ref":"/docs/concepts/architecture/","title":"Architecture"},{"body":" Storage     Indexing     ","excerpt":" Storage     Indexing     ","ref":"/docs/deploy/config/","title":"Configuration"},{"body":"In order to start developing using Docker, first deploy the stack using the directions. You can deploy the stack using SQLite, MySQL, or PostgreSQL as a backend data store.\nBuilding Local Changes To help facilitate contributions, each project has a docker target that builds the project inside a container.\n   Project Managed by docker Target     Golang Makefile make docker   NodeJS package.json npm run docker    The target produces a tagged image that you can deployed using the docker deployment.\nDeploying Local Changes Once you\u0026rsquo;ve produced an image containing your local changes, you can easily update your stack to pick up the new image.\n$ docker-compose up -d ","excerpt":"In order to start developing using Docker, first deploy the stack using the directions. You can …","ref":"/docs/contrib/docker/","title":"Developing in Docker"},{"body":"gRPC is a remote procedure call framework used to facilitate inter-process communication. Originally open sourced by Google, the framework has been adopted my many companies like Square, Netflix, and Cisco. While many companies have adopted gRPC internally, few have leveraged it closer to the edge. In this post, we will demonstrate how we set up a public facing gRPC service.\nBefore getting too far into things, it\u0026rsquo;s important to first understand the benefits and challenges when using gRPC.\nBenefits to using gRPC  Generic service definition language Code generation support for 12 languages Support for bi-directional streaming APIs, enabling more complex APIs Integrated authentication  Challenges with gRPC  Requires HTTP/2 all the way through the call stack  When connecting through a proxy service like on Cloudflare, connections often degrade to HTTP/1.1   Browser based user experiences requires support from the ecosystem  REST endpoints not available out of box Browser based calls require use of grpc-web    Due to potential protocol downgrades, it\u0026rsquo;s important to verify this is a possible solution for your stack. For example, some load balancer implementations do not support HTTP/2. You should check with your cloud provider to see if they offer either an HTTP/2 compatible, or a layer 4 load balancer.\nIf you\u0026rsquo;re connecting through a Kubernetes ingress, then you will need to ensure that your ingress controller supports gRPC. I\u0026rsquo;ve found this table to be valuable when evaluating ingress solutions. It breaks down common features across ingress controllers, popular implementations, and their support.\nServing REST and gRPC on the same address Once you\u0026rsquo;ve verified that your providers can support HTTP/2 you can start to think about code. api.deps.cloud not only provides a RESTful interface, but a gRPC one as well. As a consumer of a service, I find this to be a really convenient feature. We\u0026rsquo;re able to do this using the grpc-gateway project and some clever structuring of server handlers. The Golang snippet below walks you through the general setup.\nimport ( \u0026#34;github.com/depscloud/api/v1alpha/tracker\u0026#34; \u0026#34;github.com/depscloud/gateway/internal/proxies\u0026#34; \u0026#34;github.com/grpc-ecosystem/grpc-gateway/runtime\u0026#34; \u0026#34;github.com/rs/cors\u0026#34; \u0026#34;golang.org/x/net/http2\u0026#34; \u0026#34;golang.org/x/net/http2/h2c\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; ) func main() { // set up all servers.  grpcServer := grpc.NewServer() restServer := runtime.NewServeMux() httpServer := http.NewServeMux() // register all services with both grpc and rest.  sourceService := tracker.NewSourceServiceClient(trackerConn) tracker.RegisterSourceServiceServer(grpcServer, proxies.NewSourceServiceProxy(sourceService)) _ = tracker.RegisterSourceServiceHandlerClient(ctx, restServer, sourceService) // ...  // detect and handle grpc requests.  // this approach does incur a small performance penalty,  // but is pretty acceptable for communication happening at the edge.  httpServer.HandleFunc(\u0026#34;/\u0026#34;, func(writer http.ResponseWriter, request *http.Request) { if request.ProtoMajor == 2 \u0026amp;\u0026amp; strings.HasPrefix(request.Header.Get(\u0026#34;Content-Type\u0026#34;), \u0026#34;application/grpc\u0026#34;) { grpcServer.ServeHTTP(writer, request) } else { restServer.ServeHTTP(writer, request) } }) // go\u0026#39;s http server only supports secure HTTP/2 out of box.  // wrap with h2c for plaintext (i.e. if you do TLS termination elsewhere.)  h2cServer := h2c.NewHandler(httpServer, \u0026amp;http2.Server{}) // wrap with CORS to support cross-origin requests.  apiServer := cors.Default().Handler(h2cServer) } That\u0026rsquo;s it! Working around TLS termination can be a bit tricky. For a closer look at our implementation, take a look at the gateway process. This typically sits behind a reverse proxy and mediates communication with the backend services.\nConfiguring an ingress controller Regardless of where you\u0026rsquo;re running, you\u0026rsquo;ll probably need to do some amount of special configuration to enable gRPC. In Kubernetes, this is often done through the use of annotations. While each ingress controller uses a different annotation, the practice tends to be the same. Below, you will find an example configuration for the Kubernetes nginx-ingress.\napiVersion:networking.k8s.io/v1beta1kind:Ingressmetadata:namespace:depscloudname:depscloudannotations:# cert-manager# Sets up certificates for HTTPS support using different issuers. kubernetes.io/tls-acme:\u0026#34;true\u0026#34;cert-manager.io/cluster-issuer:\u0026#34;letsencrypt\u0026#34;# ingress controller# identify the ingress class to handle this definition,# if you should force SSL connections,# or if you need to swap protocols (i.e. terminate TLS)kubernetes.io/ingress.class:\u0026#34;nginx\u0026#34;nginx.ingress.kubernetes.io/ssl-redirect:\u0026#34;true\u0026#34;nginx.ingress.kubernetes.io/backend-protocol:\u0026#34;GRPC\u0026#34;nginx.ingress.kubernetes.io/enable-cors:\u0026#34;true\u0026#34;spec:tls:- hosts:- depscloud.company.netsecretName:api-certsrules:- host:depscloud.company.nethttp:paths:- path:/backend:serviceName:depscloud-gatewayservicePort:80Connecting a client application If you force SSL, you want to make sure clients pass along SSL credentials. When using LetsEncrypt, you shouldn\u0026rsquo;t need to pass in any certificates. Simply instantiate empty SSL credentials.\nHere\u0026rsquo;s an example using Go.\npackage main import ( \u0026#34;crypto/tls\u0026#34; \u0026#34;github.com/depscloud/api/v1alpha/tracker\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;google.golang.org/grpc/credentials\u0026#34; ) func main() { target := \u0026#34;depscloud.company.net:443\u0026#34; creds := credentials.NewTLS(\u0026amp;tls.Config{}) conn, _ := grpc.Dial(target, grpc.WithTransportCredentials(creds)) defer conn.Close() dependencyService := tracker.NewDependencyServiceClient(conn) resp, _ := dependencyService.ListDependents(\u0026amp;tracker.DependencyRequest{ Language: \u0026#34;go\u0026#34;, Organization: \u0026#34;github.com\u0026#34;, Module: \u0026#34;depscloud/api\u0026#34;, }) for _, dependent := range resp.GetDependents() { // ...  } } Here\u0026rsquo;s another example using NodeJS.\nconst grpc = require(\u0026#34;@grpc/grpc-js\u0026#34;); const { DependencyService } = require(\u0026#34;@depscloud/api/v1alpha/tracker\u0026#34;); async function main() { const target = \u0026#34;depscloud.company.net:443\u0026#34;; const creds = grpc.credentials.createSsl(); const dependencyService = new DependencyService(target, creds); dependencyService.listDependents({ language: \u0026#34;node\u0026#34;, organization: \u0026#34;depscloud\u0026#34;, module: \u0026#34;api\u0026#34;, }, (err, { dependents }) =\u0026gt; { // ...  }) } Because gRPC offers code generation across 12 different languages, supporting new clients is easy. Simply resolve the protocol buffer definition, supply the plugin to the compiler, and generate!\n","excerpt":"gRPC is a remote procedure call framework used to facilitate inter-process communication. Originally …","ref":"/blog/2020/07/03/user-facing-grpc-services/","title":"User-facing gRPC services"},{"body":"The term \u0026lsquo;master\u0026rsquo; is used heavily across the technical community. It\u0026rsquo;s used to represent primary instances in a database, branches in repositories, and so much more. But this term is also associated with racism, oppression, violence, and hate.\nTo help show our support for the black community, the default branch has been renamed to main. While this is one small change in one project, we hope that many others follow suit.\nIf you are contemplating making a similar change, it was easy to do with some shell scripting. The deps.cloud projects took about 30 minutes to migrate, including content auditing. You can follow along with the snippet below as it was used to move the deps.cloud ecosystem. While this script is specific to GitHub, it should be easy to modify for other systems.\n# setup credentials for the api export GITHUB_AUTHORIZATION=\u0026#34;token OAUTH-TOKEN\u0026#34; export GITHUB_GROUP=\u0026#34;depscloud\u0026#34; export BRANCH_NAME=\u0026#34;main\u0026#34; # start with a fresh copy of your code (just to be safe) curl -sSL -H \u0026#34;Authorization: ${GITHUB_AUTHORIZATION}\u0026#34; https://api.github.com/users/${GITHUB_GROUP}/repos | \\  jq -r .[].ssh_url | \\  xargs -I{} git clone {} # checkout a new branch and push it find . -maxdepth 2 -name .git | \\  xargs dirname | \\  xargs -I{} git --git-dir={}/.git --work-tree={} checkout -b ${BRANCH_NAME} find . -maxdepth 2 -name .git | \\  xargs dirname | \\  xargs -I{} git --git-dir={}/.git --work-tree={} push -u origin ${BRANCH_NAME} # update the default branch find . -maxdepth 2 -name .git | \\  xargs dirname | \\  xargs basename -a | \\  xargs -I{} echo https://api.github.com/repos/${GITHUB_GROUP}/{} | \\  xargs -I{} curl \\  -X PATCH \\  -H \u0026#34;Content-Type: application/json\u0026#34; \\  -H \u0026#34;Authorization: ${GITHUB_AUTHORIZATION}\u0026#34; \\  -d \u0026#34;{\\\u0026#34;default_branch\\\u0026#34;: \\\u0026#34;${BRANCH_NAME}\\\u0026#34;}\u0026#34; {} ## ## Congratulations! ## ## You\u0026#39;ve gotten to the point where active development should no longer be against master. ## Now, you don\u0026#39;t want to go and delete it quite yet as you might have some external links pointing to the branch. ## You\u0026#39;ll want to make sure you do an audit of your projects content, badges, and workflows. ## Once you\u0026#39;ve verified all the references have been updated, you\u0026#39;ll be able to proceed on. ## ## Notes: ## * Some system may require making some additional changes (like setting up protected branches). ## # delete the master branch find . -maxdepth 2 -name .git | \\  xargs dirname | \\  xargs -I{} git --git-dir={}/.git --work-tree={} push origin :master ","excerpt":"The term \u0026lsquo;master\u0026rsquo; is used heavily across the technical community. It\u0026rsquo;s used to …","ref":"/blog/2020/06/13/new-default-branch-main/","title":"New default branch: main"},{"body":"","excerpt":"","ref":"/blog/","title":"Blog"},{"body":"Welcome to the deps.cloud blog! It will be an easy way to stay on top of the latest news, release notes, and updates from the community. Since the project contains several pieces, it can be hard to track progress across all of them. This enables the presentation of cross-cutting features and larger changes to the ecosystem.\nContributors and consumers are welcome to generate content for the blog. For contributors, it\u0026rsquo;s a great way to showcase a feature you\u0026rsquo;ve contributed to the project. For consumers, it\u0026rsquo;s an opportunity to discuss how it\u0026rsquo;s been able to help benefit your ecosystems.\nWe look forward to your contributions!\n","excerpt":"Welcome to the deps.cloud blog! It will be an easy way to stay on top of the latest news, release …","ref":"/blog/2020/06/06/introducing-the-deps.cloud-blog/","title":"Introducing the deps.cloud blog"},{"body":"Prior to the command line tool (CLI) existing, the only way to interact with the system was through the RESTful API. It helps obfuscate the specifics about each endpoint by encapsulating them behind a target. Currently, this tool provides read only access to API.\n$ deps get -h Retrieve information from the graph Usage: deps get [command] Available Commands: dependencies Get the list of modules the given module depends on dependents Get the list of modules that depend on the given module modules Get a list of modules from the service sources Get a list of source repositories from the service Flags: -h, --help help for get Use \u0026#34;deps get [command] --help\u0026#34; for more information about a command. Installation You can install our CLI a few different ways. On Ubuntu, you can tap our apt repository.\n$ echo \u0026#34;deb [trusted=yes] https://apt.fury.io/depscloud/ /\u0026#34; | sudo tee /etc/apt/sources.list.d/depscloud.list $ sudo apt-get update $ sudo apt-get install depscloud-cli $ deps version deps {version: 0.0.13, commit: a99e9a737103b7b79294b3b754e005c49267cdbd, date: 2020-06-27T22:21:27Z} On OSX, you can tap our Homebrew repository.\n$ brew tap depscloud/tap $ brew install depscloud-cli $ deps version deps {version: 0.0.13, commit: a99e9a737103b7b79294b3b754e005c49267cdbd, date: 2020-06-27T22:21:27Z} Finally, you can download the latest deps binary from GitHub releases.\nhttps://github.com/depscloud/depscloud/releases/latest\nConfiguration The deps can be configured to point at a custom deployment of the deps.cloud ecosystem. This is done using the DEPSCLOUD_BASE_URL environment variable. Here\u0026rsquo;s an example of how to configure it to use the public API (default behavior)\nexport DEPSCLOUD_BASE_URL=\u0026#34;https://api.deps.cloud\u0026#34; If you\u0026rsquo;re trying things out locally, you can also point it at an instance running in docker.\nexport DEPSCLOUD_BASE_URL=\u0026#34;http://localhost:8080\u0026#34; Use Cases There are many use cases that this tool supports. This section details several sample queries to help get folks started.\nModules Modules represent both libraries and applications in the dependency graph. These can be queried for in one of two ways. The first option is to list all modules the service knows about.\n$ deps get modules ... The second option is to list all modules produced by a given repository. To query for this information, simply add the --url or -u flag.\n$ deps get modules -u https://github.com/depscloud/api.git {\u0026#34;manages\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;system\u0026#34;:\u0026#34;vgo\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;latest\u0026#34;},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/api\u0026#34;}} {\u0026#34;manages\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;node\u0026#34;,\u0026#34;system\u0026#34;:\u0026#34;npm\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;0.1.0\u0026#34;},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;node\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;depscloud\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;api\u0026#34;}} Sources Currently, a source represents a repository. It can later be used to represent other sources of dependency information (like Nexus and other artifact repositories). Similar to modules, sources can queried multiple ways. The first option is to list all sources the service knowns about.\n$ deps get sources ... The second option is to list all sources for a given module. To query or this information, the --language, --organization, and --module flags must be provided. Alternatively, the corresponding shorthands -l, -o, and -m can be used respectively.\n$ deps get sources -l go -o github.com -m depscloud/api {\u0026#34;source\u0026#34;:{\u0026#34;url\u0026#34;:\u0026#34;https://github.com/depscloud/api.git\u0026#34;},\u0026#34;manages\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;system\u0026#34;:\u0026#34;vgo\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;latest\u0026#34;}} Dependents Dependent modules are those who consume the module you\u0026rsquo;re querying for. That is, modules who list your module as a dependency.\n$ deps get dependents -l go -o github.com -m depscloud/api {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.1.0\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/gateway\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.1.0\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/tracker\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.1.0\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/indexer\u0026#34;}} Dependencies Dependencies are the modules that your module requires. This should rarely differ from the modules you list in your appropriate manifest file (package.json, go.mod, etc.)\n$ deps get dependencies -l go -o github.com -m depscloud/api {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v1.3.0\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;gogo/protobuf\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.3.2\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;indirect\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/text\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.0.0-20190628185345-da137c7871d7\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;indirect\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/net\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v1.3.2\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;golang/protobuf\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.0.0-20190916214212-f660b8655731\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;google.golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;genproto\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.0.0-20190626221950-04f50cda93cb\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;indirect\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/sys\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v1.11.2\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;grpc-ecosystem/grpc-gateway\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v1.23.1\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;google.golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;grpc\u0026#34;}} Topology Topologies are one of the most useful elements of a dependency graph. They can provide you with the full set of transitive modules, build orders, and notions of parallelism.\nThis is largely because topological queries can be resource intensive. This is due to the fact that the subgraph needs to be buffered before any results can be returned. By implementing this as a client-side feature, we defer the memory/disk cost to clients, allowing them to buffer as they see fit while allowing the tracker to be light weight.\nTopologies can be queried in both the dependencies and dependents direction.\n$ deps get dependencies topology -l go -o github.com -m depscloud/api {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/api\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;gogo/protobuf\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/text\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/net\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;golang/protobuf\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;google.golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;genproto\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/sys\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;grpc-ecosystem/grpc-gateway\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;google.golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;grpc\u0026#34;} $ deps get dependents topology -l go -o github.com -m depscloud/api {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/api\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/gateway\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/cli\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/tracker\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/indexer\u0026#34;} By adding the --tiered flag, you will get a structured set of results back. This is great for building automation around your source code as it not only identifies the order in which things should be built, but it also provides tiers where parallel builds can occur. Consider the following simple example.\n$ deps get dependents topology -l go -o github.com -m depscloud/api --tiered [{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/api\u0026#34;}] [{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/gateway\u0026#34;},{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/cli\u0026#34;},{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/tracker\u0026#34;},{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/indexer\u0026#34;}] In this case, we only have two tiers. Each tier contains a list of modules that can be built in parallel. When one tier is complete, the next tier can be processed safely without worrying about transitive dependency issues.\n","excerpt":"Prior to the command line tool (CLI) existing, the only way to interact with the system was through …","ref":"/docs/guides/cli/","title":"Command Line"},{"body":"All projects are open to contributions. Be sure to consult all the resources below prior to contributing.\nProcess and Project Management The deps.cloud project leverages a public GitHub Project for tracking its work items. For new comers, there\u0026rsquo;s a section that provides some detail around how to get started developing on the project. If you want to submit an issue, you can open one up under the deps.cloud project. A triager will take care of moving it to the right project.\nContributor Agreements To help protect the project owners and contributors to the project, we\u0026rsquo;ve established a common set of CLAs. The Individual Contributor Agreement should be signed by anyone who submits code to the project. The Corporate Contributor Agreement should be signed by any organization whose engineers are submitting code on their behalf.\nIndividual Contributors For the individual contributor agreement, we leverage cla-assistant.io. A copy of this agreement can be found here. This agreement will need to be signed by anyone looking to contribute code to the project. To sign this agreement, you can go here and sign using your github account:\nhttps://cla-assistant.io/depscloud/deps.cloud\nCorporate Contributors If you are submitting code on behalf of your company, please ensure your company has submit a copy of our Corporate Contributor Agreement. You can find a copy of the corporate agreement here. When complete, you can email a copy of it to us.\n","excerpt":"All projects are open to contributions. Be sure to consult all the resources below prior to …","ref":"/docs/contrib/","title":"Contributing"},{"body":"        Track, monitor, and connect project dependencies across different languages and toolchains.                                Learn More  Supported Manifests        ","excerpt":"        Track, monitor, and connect project dependencies across different languages and toolchains. …","ref":"/","title":"deps.cloud"},{"body":"deps.cloud is a tool built to help companies understand how projects relate to one another. It does this by detecting dependencies defined in common manifest files. Using this information, we\u0026rsquo;re able to construct a dependency graph. As a result we\u0026rsquo;re able to answer questions like:\n Which projects have been indexed? Which libraries get produced by a project? Which libraries do I depend on and what version? Which projects depend on library X and what version? Which projects can produce library X? Which projects do our systems use the most?    Concepts Learn more about the concepts and terminology behind the system, it\u0026#39;s data model, and architecture.\n    Deployment Learn how to configure and deploy the deps.cloud ecosystem locally or to clustered environments.\n    User Guides Learn how to consume data from the API and use it to build further capabilities.\n    Contributing Learn how to give back and contribute to the project. From where to find help to getting started.\n     ","excerpt":"deps.cloud is a tool built to help companies understand how projects relate to one another. It does …","ref":"/docs/","title":"Documentation"},{"body":"","excerpt":"","ref":"/search/","title":"Search Results"}]