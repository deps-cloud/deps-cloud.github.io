[{"body":"-- deps.cloud is a tool built to help engineers understand how their projects relate to one another. When an organization is small, this is a rather easy thing to do. As an organization grows, the number of repositories often grow as well. As the number repositories grow, reasoning about how they relate to one another often becomes a challenge.\nTo solve this problem, deps.cloud stores information in a queryable dependency graph. It does this by parsing and indexing manifest files that communicate a given projects requirements. In NodeJS, this is often a package.json file. In Java, a pom.xml or build.gradle.\nWhat problems can deps.cloud solve? Identify heavily used open source solutions across your code base\nRegardless of organization size, deps.cloud can help track open source libraries and their use across your ecosystem. Monitor direct consumers of an open source project as well as the full dependency tree.\nRefactor interfaces and clean up deprecated code\nChanging existing interfaces can often be problematic. You often need to provide two versions of a method, publish a new version of the library, update all consumers, and remove the old method. This process can often take several versions to roll through completely. With deps.cloud, you can be proactive in propagating changes across library consumers.\nPropagate updates for security vulnerabilities across impacted projects\nUsing libraries means you eventually have to handle an upgrade to address a CVE. deps.cloud not only show what systems are consuming a potentially vulnerable library, but also the versions used by your ecosystem.\nFurther Reading  Manifest Files Architecture Integrations  ","excerpt":"-- deps.cloud is a tool built to help engineers understand how their projects relate to one another. …","ref":"/docs/what-is-depscloud/","title":"What is deps.cloud?"},{"body":"A manifest is the generic term used to describe documents that communicate a systems requirements or dependencies. These dependencies come in many shapes and forms, but the most common dependency is a library. Libraries are packages containing common code that is shared between projects.\nUsing this information, deps.cloud is able to build a knowledge graph. The table below demonstrates how this information is extracted from various manifests. Since there is no standardization across languages, extraction may vary between implementations.\n   Manifest File Language System Example Organization Module     bower.json node bower @depscloud/api depscloud api   build.gradle, settings.gradle java gradle com.google.guava:guava com.google.guava guava   cargo.toml rust cargo bytes _ bytes   composer.json php composer symfony/console symfony console   Godeps.json go godeps github.com/depscloud/api github.com depscloud/api   go.mod go vgo github.com/depscloud/api github.com depscloud/api   Gopkg.toml go gopkg github.com/depscloud/api github.com depscloud/api   ivy.xml java ivy com.google.guava;guava com.google.guava guava   package.json node npm @depscloud/api depscloud api   pom.xml java maven com.google.guava;guava com.google.guava guava   vendor.conf go vendor github.com/depscloud/api github.com depscloud/api    ","excerpt":"A manifest is the generic term used to describe documents that communicate a systems requirements or …","ref":"/docs/manifests/","title":"Manifest Files"},{"body":"This page serves as documentation of the open source architecture for the deps.cloud system.\nOverview While there are several components that make up the ecosystem, each of them serve their own purpose.\nComponents Gateway is the face of the API services. It provides a RESTful HTTP interface to the backing gRPC services. See the gateway docs for more information.\nTracker provides several APIs for navigating the graph of information. This service leverages other storage systems such as SQLite or MySQL to store the graph data. See the tracker docs for more information.\nExtractor is responsible for looking at different manifest files and extracting dependency information from them. This mechanism is easily pluggable to support a large range of different manifest files. See the extractor docs for more information.\nThe indexer is responsible for fetching repository information, cloning and crawling it, leveraging the extractor and tracker where appropriate. See the indexer docs for more information.\nThe command line interface or CLI provides end users with an easy ability to query the API. See the CLI docs for more information.\nDesign Decisions As this system was built out, there were several key decisions that were made along the way. In this section, I capture several of the frequently asked questions and document the rationale behind them.\nHow should services communicate? There are many different ways services can communicate. REST and gRPC are simply two of them. While there are many options out there, there were many benefits that came along with leveraging gRPC. This includes, but is not limited to:\n contractual API definitions using Protocol Buffers support for multi-language systems built in client side load balancing and health checking  In the end, I decided to leverage gRPC. As a result, it\u0026rsquo;s had a great impact on the ecosystem. It allowed parts to be prototyped in one language, and rewritten when they didn\u0026rsquo;t scale. Adding REST support was easy with the help of the grpc-gateway project.\nHow should the data be stored? When you think of a dependency graph, it\u0026rsquo;s easy to jump to the conclusion to use one of the existing graph databases out there. However, when working with folks in the open source community, it\u0026rsquo;s hard to find people with prior experience on graph databases. Most people are still more familiar with things like MySQL or MongoDB.\nKnowing this layer of the stack was likely to be swapped out with Company X\u0026rsquo;s preferred store, I wanted it to be pluggable. So the first implementation was on top of an SQL system. From there, we were able to extract a simple service interface. This makes it easy to swap the storage technology out for different solutions.\nFor more information on the data layer, see the Data Model documentation.\n","excerpt":"This page serves as documentation of the open source architecture for the deps.cloud system. …","ref":"/docs/architecture/","title":"Architecture"},{"body":" Repository: https://github.com/depscloud/gateway Runtime: Golang Language: Golang  Background Gateway is an extremely thin, lightweight, reverse proxy. It provides a RESTful interface that translates requests into gRPC calls. This is done using the grpc-gateway project. grpc-gateway provides a library and several Protocol Buffer plugins. These plugins make it possible to annotate service calls defined in .proto files with RESTful semantics. These annotations generate associated HTTP handlers and Swagger documentation.\nIn addition to servicing requests, it aggregates both the extractor and tracker systems behind a single interface. This makes configuring tools like the CLI a lot easier.\nSwagger Explorers In addition to serving the API, it also serves the associated swagger documentation. You can explore the API further at the links below.\n Extractor Swagger Tracker Swagger  ","excerpt":"Repository: https://github.com/depscloud/gateway Runtime: Golang Language: Golang  Background …","ref":"/docs/services/gateway/","title":"Gateway"},{"body":"GitHub is the largest source of repositories. Most companies have an account where they maintain their code repositories. Due to the system\u0026rsquo;s popularity, it was one of the first integrations that was targeted. Below, you\u0026rsquo;ll find the full set of configuration options that can be specified for a GitHub account.\naccounts:# full github schema- github:base_url:\u0026lt;base_url\u0026gt; upload_url: \u0026lt;base_url\u0026gt;users:- \u0026lt;username\u0026gt; organizations:- \u0026lt;organization\u0026gt; strategy: SSH | HTTPoauth2:token:\u0026lt;oauth_token\u0026gt; token_type: \u0026lt;token_type\u0026gt;refresh_token:\u0026lt;refresh_token\u0026gt; expiry: \u0026lt;expiry\u0026gt;Due to the variance in each of the client, there are a few oddities between each of the implementations. While we work on getting parity between each of the providers take note that this implementation:\n does not pull groups for the authenticated user pull groups for the configured users pulls repositories for all users and groups (configured and discovered)  Example Crawl all of Google\u0026rsquo;s public repositories on GitHub.\naccounts:- github:organizations:- googlestrategy:HTTP","excerpt":"GitHub is the largest source of repositories. Most companies have an account where they maintain …","ref":"/docs/integrations/github/","title":"GitHub"},{"body":"Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nOur Standards Examples of behavior that contributes to creating a positive environment include:\n Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members  Examples of unacceptable behavior by participants include:\n The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others\u0026rsquo; private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting  Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\nScope This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\nEnforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project owner on Gitter. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project\u0026rsquo;s leadership.\nAttribution This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\nFor answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq\n","excerpt":"Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and …","ref":"/docs/contributing/code-of-conduct/","title":"Code of Conduct"},{"body":"In this quick start guide, we\u0026rsquo;ll use docker-compose to create our demo infrastructure.\nTo get started quickly, you should clone the deploy repository and leverage the configuration under the docker directory.\n1 - Launch deps.cloud To launch the demo infrastructure, simply run the following:\n$ docker-compose up -d Creating docker_extractor_1 ... done Creating docker_tracker_1 ... done Creating docker_indexer_1 ... done Creating docker_gateway_1 ... done That\u0026rsquo;s it!\nThe deps.cloud demo infrastructure is up and running. You can test it out by opening any of the following endpoints (browser or curl).\n What sources have been indexed? What modules are produced by this repository? What modules do I depend on and what version? What modules depend on me and what version? What repositories can produce this module?  2 - Configure Your Provider Once the demo infrastructure is up and running, you can easily modify the rds.yaml file to include more accounts to index. For more information on how to configure each integration, see the integrations section. For now, let\u0026rsquo;s simply add your GitHub ID to the existing block.\naccounts: - github: strategy: HTTP users: - { .GitHubLogin } organizations: - depscloud The configuration will not be automatically reloaded. Any process consuming the configuration will need to be restarted.\n3 - Rerun Indexer The indexer process is typically run as a cronjob. Because of this, it will typically pick up the configuration on it\u0026rsquo;s next run. When running locally, we can restart the process to pick up the new configuration. You may need to re-create the container.\n$ docker-compose restart indexer Restarting docker_indexer_1 ... done ","excerpt":"In this quick start guide, we\u0026rsquo;ll use docker-compose to create our demo infrastructure.\nTo get …","ref":"/docs/deployment/docker/","title":"Docker"},{"body":"This page serves as documentation of the open source data model for the deps.cloud system.\nLogical Model The logical model is the user facing representation of the data in the system. It is defined using protocol buffers. The complete schema can be found in the API repository. To summarize, there are four distinct entities in the deps.cloud database.\nSources represent origins for information. These can be source control systems like GitHub, GitLab, or BitBucket. Or they can be artifactories like JFrog Artifactory or Sonatype Nexus. Sources are keyed by their URL and are represented as nodes in the dependency graph.\nModules represent libraries or applications in the dependency graph. Modules are extracted from manifest files. They are keyed by all their data, and are represented as nodes in the dependency graph.\nManages represent the relationship between a source and a module. It contains information about how a given module is managed such as the toolchain.\nDepends represents the relationship between two modules. It contains information about how the modules depend on one another. This includes things like version constraint, scopes, and a reference to the source.\nThis data can be visualized as such:\nDatabase Schema The database schema was inspired by EdgeStore at Dropbox. With a few modifications, we were able to successfully model a dependency graph. Below, you will find a copy of a create table statement for MySQL.\nCREATE TABLE IF NOT EXISTS `dts_graphdata` ( `graph_item_type` varchar(55) NOT NULL, `k1` char(64) NOT NULL, `k2` char(64) NOT NULL, `k3` varchar(64) NOT NULL, `encoding` tinyint DEFAULT NULL, `graph_item_data` text, `last_modified` datetime DEFAULT NULL, `date_deleted` datetime DEFAULT NULL, PRIMARY KEY (`graph_item_type`,`k1`,`k2`,`k3`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci This schema is able to represent a dependency graph with the help of a few simple rules.\n When k1 == k2, the row represents a node in the graph When k1 != k2, the row represents an edge between k1 and k2 k3 allows for multiple edges to exist between nodes, but is restricted to one per source  To help make this more concrete, consider the following simplified table:\n| graph_item_type | k1 | k2 | k3 | encoding | graph_item_data | |-----------------|--------|--------|--------|----------|-----------------| | depends | msha | osha | ssha | 1 | { ... } | | manages | ssha | msha | | 1 | { ... } | | module | msha | msha | | 1 | { ... } | | module | osha | osha | | 1 | { ... } | | source | ssha | ssha | | 1 | { ... } | The following statements can be made about the data shown in the table.\n Source ssha manages module msha. Module msha depends on module osha for source ssha.  Swappable Storage Engines While only SQL support is available today, it\u0026rsquo;s possible to support NoSQL systems too. This is made possible by the simplified schema and data abstraction layer. Current database support:\n SQLite MySQL Postgres  ","excerpt":"This page serves as documentation of the open source data model for the deps.cloud system.\nLogical …","ref":"/docs/data-model/","title":"Data Model"},{"body":"Online The team has used several communication tools. Like most projects, we wound up on Slack. If you have trouble joining, please do not hesitate to reach out to the mailing list for additional support.\nMeetings Until further notice community meetings have been paused. If large enough interest has been expressed, we can start them back up again.\n ","excerpt":"Online The team has used several communication tools. Like most projects, we wound up on Slack. If …","ref":"/docs/contributing/community/","title":"Community"},{"body":" Repository: https://github.com/depscloud/indexer Runtime: Golang Language: Golang  Background The indexer process often runs as a cron job. On a configured schedule, it will re-index all available repositories. While not ideal, this solution provides an easy way to get started. If needed, the indexing process can be sharded across multiple different indexers. This will allow some indexers to run on more frequent intervals while others run on less frequent ones.\nOn Cloning When the indexer clones a repository, it uses /tmp to create an ephemeral directory. It then performs a shallow clone of a repository into that tmp directory. When the indexing process is complete, all of this is cleaned up.\nOne thing to be wary of when deploying to your infrastructure is the concurrency induced by the number of --workers. A single worker can process many repositories fairly quick. Two workers is often more than sufficient.\n","excerpt":"Repository: https://github.com/depscloud/indexer Runtime: Golang Language: Golang  Background The …","ref":"/docs/services/indexer/","title":"Indexer"},{"body":"This guide explains how to run the deps.cloud infrastructure within a Kubernetes cluster.\nPrerequisites  A working Kubernetes cluster. To follow along with this guide, you should set up minikube on your machine. Minikube provides a great way to test and experiment around with Kubernetes locally. The kubectl binary should be installed and in your path on your workstation.  1 - Configure a Storage Class deps.cloud leverages MySQL to store a given graphs dependency information. MySQL requires a persistent volume to be able to ensure the data is persisted to disk. In Kubernetes, a Persistent Volume can either be manually provisioned by a System Administrator or Dynamically provisioned using a Storage Class. To figure out if you need to install a Storage Class, you can use kubectl to see which ones have been configured on the cluster already.\n$ kubectl get storageclasses.storage.k8s.io NAME PROVISIONER AGE standard (default) k8s.io/minikube-hostpath 14d If you\u0026rsquo;re have none, you can configure a local-storage class. This leverages the storage provided by the host that the pod is running on. It also creates an affinity so that the next time the pod restarts, it will prefer that host over the others.\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: local-storage provisioner: kubernetes.io/no-provisioner volumeBindingMode: WaitForFirstConsumer EOF 2 - Set-up Workspace Before deploying any workloads, we first need a workspace to deploy into. The following command creates a Kubernetes namespace with the name depscloud.\n$ kubectl create ns depscloud Once created, Network Policies, Resource Quotas, and RBAC can be used to lock down the system. All the resources created in this walk through will be deployed to this namespace.\n3 - Deploy MySQL If you don\u0026rsquo;t already have a MySQL database available, you can deploy one using one of the many helm charts out there. The following deployment was generated from the bitnami/mysql.\n$ kubectl apply -n depscloud -f https://depscloud.github.io/deploy/k8s/mysql.yaml This deployment comes with a single primary node and a read only replica node.\n4 - Configure deps.cloud By default, the tracker and indexer do not come configured. This allows operators to connect it to provide their specific configuration. To configure these processes, you\u0026rsquo;ll need to create two secrets in the depscloud namespace.\nTo configure the tracker, you\u0026rsquo;ll need to provide a depscloud-tracker secret. This secret is used to connect the tracker to the previously provisioned MySQL database.\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: Secret metadata: namespace: depscloud name: depscloud-tracker stringData: STORAGE_DRIVER: mysql STORAGE_ADDRESS: user:password@tcp(mysql:3306)/depscloud STORAGE_READ_ONLY_ADDRESS: user:password@tcp(mysql-slave:3306)/depscloud EOF To configure the indexer, you\u0026rsquo;ll need to provide a depscloud-indexer secret. This file tells the indexer how to discovery and clone repositories. The following configuration will index the deps.cloud repositories.\n$ cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: Secret metadata: namespace: depscloud name: depscloud-indexer stringData: config.yaml: | accounts: - github: strategy: HTTP organizations: - depscloud EOF You can learn more about how to configure the indexer process on the integrations page.\n4 - Deploy deps.cloud After the tracker and indexer have been configured, you\u0026rsquo;ll be able to deploy the deps.cloud infrastructure. This configuration can be found with the other deployment configuration on GitHub.\n$ kubectl apply -n depscloud -f https://depscloud.github.io/deploy/k8s/depscloud-system.yaml Once all processes have completed and are healthy, you should be able to interact with the API pretty easily. To quickly test this, you can port forward to one of the gateway pods directly.\n$ kubectl port-forward -n depscloud svc/depscloud-gateway 8080:80 Forwarding from 127.0.0.1:8080 -\u0026gt; 8080 Forwarding from [::1]:8080 -\u0026gt; 8080 Once the port is forwarded, the following endpoints should be able to be reached.\n What sources have been indexed? What modules are produced by this repository? What modules do I depend on and what version? What modules depend on me and what version? What repositories can produce this module?  ","excerpt":"This guide explains how to run the deps.cloud infrastructure within a Kubernetes cluster. …","ref":"/docs/deployment/k8s/","title":"Kubernetes"},{"body":"GitLab is a common provider used by those seeking an on-premise solution who do not want their source code managed by a third party provider. Many companies choose to run this system internally. Below, you will find the list of options that can be configured to get the system running. Either private or oauth should be provided. Otherwise, you will only have access to public repositories. I\u0026rsquo;ve found configuring the private token to be the easiest.\naccounts:# full gitlab schema- gitlab:base_url:\u0026lt;base_url\u0026gt; users:- \u0026lt;username\u0026gt; groups:- \u0026lt;groupname\u0026gt; strategy: SSH | HTTPprivate:token:\u0026lt;private_token\u0026gt; oauth:token:\u0026lt;oauth_token\u0026gt; application_id: \u0026lt;application_id\u0026gt;Due to the variance in each of the client, there are a few oddities between each of the implementations. While we work on getting parity between each of the providers take note that this implementation:\n pulls groups for the authenticated user does not pull groups for the configured users pulls repositories for all users and groups (configured and discovered)  Example Crawl all of Nvidia\u0026rsquo;s public repositories on GitLab.\naccounts:- gitlab:groups:- nvidiastrategy:HTTP","excerpt":"GitLab is a common provider used by those seeking an on-premise solution who do not want their …","ref":"/docs/integrations/gitlab/","title":"GitLab"},{"body":"This section provides guidance on how to configure the underlying system. Keep in mind, how you update the configuration depends on your deployment strategy. If you\u0026rsquo;re using Docker, you will be changing the config.yaml file. If you\u0026rsquo;re using Kubernetes, you will need to change the config.yaml key in the indexer Secret.\nDiscovery is responsible for the discovery of repositories from different sources. These sources include systems like BitBucket, GitHub, and GitLab. Configuring the system to read from these different sources is rather easy. See the following configuration guides on how to configure the system for your corresponding provider.\n GitHub Index user and organization repositories.\n    GitLab Index user and group repositories.\n    BitBucket Index user and team repositories.\n    ","excerpt":"This section provides guidance on how to configure the underlying system. Keep in mind, how you …","ref":"/docs/integrations/","title":"Integrations"},{"body":"Cloning Projects Once you\u0026rsquo;ve forked the repository, you\u0026rsquo;ll want to clone it locally for development. For convenience, I tend to work out of the GOPATH directory. Using the following command, you can quickly build a directory for all the depscloud related work.\n$ mkdir -p ${GOPATH}/src/github.com/depscloud \u0026amp;\u0026amp; cd $_ Once you have a workspace, clone the upstream project. This will allow you to regularly pull updates from the origin.\n$ git clone git@github.com:depscloud/\u0026lt;project\u0026gt;.git Building and Running Projects There are two ways you can build and run this project. First you can develop using docker (the recommended way). Each repository ships with two dockerfiles, one for building and testing locally, another for publishing. The second way to build and run this project. This mechanism is not recommended, but can often help quickly testing things without the overhead of docker.\n Developing in Docker (Recommended) Developing Locally  Branching The most common way you will likely create a branch is through the use of a GitHub issue within the repository. To create a branch for GitHub issue #11, simply create a branch with the name gh-11.\n$ git checkout -b gh-11 In some rare occasions you might be working on a issue that requires work across multiple repositories. In this case, you should used the deps.cloud repository to create a parent issue that the other issues can reference and link to. To link another projects issue, you can use the \u0026lt;user\u0026gt;/\u0026lt;project\u0026gt;#11 semantic. Similarly, you can create a feature branch using the same syntax.\n$ git checkout -b \u0026lt;user\u0026gt;/\u0026lt;project\u0026gt;#11 Forking and Submitting Pull Requests By and large, forks are used to submit pull requests to the upstream repositories.\nAfter a project has been cloned, you will need to add your fork as a remote.\n$ git remote add \u0026lt;myuser\u0026gt; git@github.com:\u0026lt;myuser\u0026gt;/\u0026lt;project\u0026gt;.git By doing this, you\u0026rsquo;re able to maintain two references: one for upstream updates and one for your set of changes. When pushing a branch to, you can specify the -u option to have your local branch track a specific remote.\n$ git push -u \u0026lt;myuser\u0026gt; gh-11 From here, all git push operations will default to using your fork. After a branch has been pushed, you can use pull requests to have your code reviewed by the team.\n","excerpt":"Cloning Projects Once you\u0026rsquo;ve forked the repository, you\u0026rsquo;ll want to clone it locally for …","ref":"/docs/contributing/git/","title":"Working with Git"},{"body":"This guide explains how to run the deps.cloud infrastructure within a Kubernetes cluster using the Helm package manager.\nPrerequisites  A working Kubernetes cluster. To follow along with this guide, you should set up minikube on your machine. Minikube provides a great way to test and experiment around with Kubernetes locally. The kubectl binary should be installed and in your path on your workstation. The helm binary should be installed and in your path on your workstation.  1 - Adding the Helm Repository In order to leverage the deps.cloud Helm charts, you first need to add the deps.cloud stable repository.\n$ helm repo add depscloud https://depscloud.github.io/deploy/charts \u0026quot;depscloud\u0026quot; has been added to your repositories $ helm repo update 2 - Deploy the deps.cloud Infrastructure Once the deps.cloud chart repository has been added, you can install the charts as follows.\n$ kubectl create ns depscloud namespace/depscloud created $ helm upgrade -n depscloud -i depscloud depscloud/depscloud Release \u0026quot;depscloud\u0026quot; does not exist. Installing it now. NAME: depscloud LAST DEPLOYED: Sat Jun 20 16:50:57 2020 NAMESPACE: depscloud STATUS: deployed REVISION: 1 TEST SUITE: None This same command can be used to upgrade the system in the future.\n3 - Querying the deps.cloud Infrastructure Once all processes have completed and are healthy, you should be able to interact with the API pretty easily. Note that there will be no data in the API until the indexer process has run. To quickly test this, you can port forward the depscloud-gateway service.\n$ kubectl port-forward -n depscloud svc/depscloud-gateway 8080:80 Forwarding from 127.0.0.1:8080 -\u0026gt; 8080 Forwarding from [::1]:8080 -\u0026gt; 8080 Once the port is forwarded, the following endpoints should be able to be reached.\n What sources have been indexed? What modules are produced by this repository? What modules do I depend on and what version? What modules depend on me and what version? What repositories can produce this module?  4 - Configuring using values.yaml A values.yaml file can be used to maintain deployment specific configuration. The content below provides an example of how to configure the indexer to crawl the depscloud account.\n# contents of values.yamlindexer:config:accounts:- github:clone:strategy:HTTPorganizations:- depscloudtracker:storage:driver:sqlite|mysql|postgresaddress:\u0026#34;\u0026#34;readOnlyAddress:\u0026#34;\u0026#34;Then during install, you can pass in the values.yaml file.\n$ helm upgrade -n depscloud -i depscloud depscloud/depscloud -f values.yaml 5 - Optional Installments The following are optional considerations. You do not need to install them to run the system, but can make managing it easier.\nIngress By using an ingress address and controller, you can easily expose the REST API.\napiVersion:networking.k8s.io/v1beta1kind:Ingressmetadata:namespace:depscloudname:depscloudspec:rules:- host:depscloud.internal.company.nethttp:paths:- path:/backend:serviceName:depscloud-gatewayservicePort:80Using helm-operator The helm-operator provided by fluxcd is an extremely powerful resource. If provides a way to manage Helm releases within a cluster through custom resource definitions.\napiVersion:helm.fluxcd.io/v1kind:HelmReleasemetadata:namespace:depscloudname:depscloudspec:releaseName:depscloudchart:repository:https://depscloud.github.io/deploy/chartsname:depscloudvalues:indexer:schedule:\u0026#34;@daily\u0026#34;config:accounts:- github:clone:strategy:HTTPorganizations:- depscloud","excerpt":"This guide explains how to run the deps.cloud infrastructure within a Kubernetes cluster using the …","ref":"/docs/deployment/helm/","title":"Helm"},{"body":"BitBucket is a common provider used by those seeking private repository support with great integration into existing Atlassian products (like Jira and Confluence). Below is the complete set of options that can be used to configure your integration. Either basic or oauth should be provided. Otherwise, you will only have access to public repositories. I\u0026rsquo;ve found that basic using an application password has been the easiest to configure.\naccounts:# full bitbucket schema- bitbucket:users:- \u0026lt;username\u0026gt; teams:- \u0026lt;teamname\u0026gt; strategy: SSH | HTTPbasic:username:\u0026lt;username\u0026gt; password: \u0026lt;app_password\u0026gt;oauth:token:\u0026lt;oauth_token\u0026gt; application_id: \u0026lt;application_id\u0026gt;Due to the variance in each of the client, there are a few oddities between each of the implementations. While we work on getting parity between each of the providers take note that this implementation:\n does not pull groups for the authenticated user does not pull groups for the configured users pulls repositories for all configured users and groups  Example Crawl all of Atlassian\u0026rsquo;s public repositories on BitBucket.\naccounts:- bitbucket:teams:- atlassianstrategy:HTTP","excerpt":"BitBucket is a common provider used by those seeking private repository support with great …","ref":"/docs/integrations/bitbucket/","title":"Bitbucket"},{"body":"The deployment of deps.cloud is easy. While there may still be some rough edges, the intent was to make it possible for any company to drop it into place. The sections below provide you with details around the various deployment options.\n Docker Deploy to a docker daemon or a swarm cluster.\n    Kubernetes Deploy to Kubernetes using raw manifest files.\n    Helm Deploy to Kubernetes using the Helm package manager.\n    ","excerpt":"The deployment of deps.cloud is easy. While there may still be some rough edges, the intent was to …","ref":"/docs/deployment/","title":"Deployment"},{"body":" Repository: https://github.com/depscloud/tracker Runtime: Golang Language: Golang  Background The tracker is a Go process used to encapsulate operations around the database. It contains four gRPC services, three of which are currently implemented. The TopologyService was initially specified but later implemented as a client-side feature. While it can be implemented on the server side, the memory and disk requirements vary greatly between queries making it difficult to size appropriately.\nSwagger Explorer By leveraging the grpc-gateway project, we\u0026rsquo;re able to easily generate Swagger documentation for the API. This allows you to leverage the Swagger UI to easily browse the API and it\u0026rsquo;s operations. For convenience, this has been embedded below.\n\t window.onload = function() { const ui = SwaggerUIBundle({ url: \"https://api.deps.cloud/swagger/v1alpha/tracker/tracker.swagger.json\", dom_id: '#ohpen_swagger_ui', presets: [ SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset ] }) window.ui = ui } \t","excerpt":"Repository: https://github.com/depscloud/tracker Runtime: Golang Language: Golang  Background The …","ref":"/docs/services/tracker/","title":"Tracker"},{"body":" Repository: https://github.com/depscloud/cli Runtime: Golang Language: Golang  Background Prior to the command line tool (CLI) existing, the only way to interact with the system was through the RESTful API. It helps obfuscate the specifics about each endpoint by encapsulating them behind a target. Currently, this tool provides read only access to API.\n$ deps get -h Retrieve information from the graph Usage: deps get [command] Available Commands: dependencies Get the list of modules the given module depends on dependents Get the list of modules that depend on the given module modules Get a list of modules from the service sources Get a list of source repositories from the service Flags: -h, --help help for get Use \u0026#34;deps get [command] --help\u0026#34; for more information about a command. Installation You can install our CLI a few different ways. On Ubuntu, you can tap our apt repository.\n$ echo \u0026#34;deb [trusted=yes] https://apt.fury.io/depscloud/ /\u0026#34; | sudo tee /etc/apt/sources.list.d/depscloud.list $ sudo apt-get update $ sudo apt-get install depscloud-cli $ deps version deps {version: 0.0.13, commit: a99e9a737103b7b79294b3b754e005c49267cdbd, date: 2020-06-27T22:21:27Z} On OSX, you can tap our Homebrew repository.\n$ brew tap depscloud/tap $ brew install depscloud-cli $ deps version deps {version: 0.0.13, commit: a99e9a737103b7b79294b3b754e005c49267cdbd, date: 2020-06-27T22:21:27Z} Finally, you can download one of the latest binaries from GitHub releases.\nhttps://github.com/depscloud/cli/releases/latest\nConfiguration The deps can be configured to point at a custom deployment of the deps.cloud ecosystem. This is done using the DEPSCLOUD_BASE_URL environment variable. Here\u0026rsquo;s an example of how to configure it to use the public API (default behavior)\nexport DEPSCLOUD_BASE_URL=\u0026#34;https://api.deps.cloud\u0026#34; If you\u0026rsquo;re trying things out locally, you can also point it at an instance running in docker.\nexport DEPSCLOUD_BASE_URL=\u0026#34;http://localhost:8080\u0026#34; Use Cases There are many use cases that this tool supports. This section details several sample queries to help get folks started.\nModules Modules represent both libraries and applications in the dependency graph. These can be queried for in one of two ways. The first option is to list all modules the service knows about.\n$ deps get modules ... The second option is to list all modules produced by a given repository. To query for this information, simply add the --url or -u flag.\n$ deps get modules -u https://github.com/depscloud/api.git {\u0026#34;manages\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;system\u0026#34;:\u0026#34;vgo\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;latest\u0026#34;},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/api\u0026#34;}} {\u0026#34;manages\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;node\u0026#34;,\u0026#34;system\u0026#34;:\u0026#34;npm\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;0.1.0\u0026#34;},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;node\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;depscloud\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;api\u0026#34;}} Sources Currently, a source represents a repository. It can later be used to represent other sources of dependency information (like Nexus and other artifact repositories). Similar to modules, sources can queried multiple ways. The first option is to list all sources the service knowns about.\n$ deps get sources ... The second option is to list all sources for a given module. To query or this information, the --language, --organization, and --module flags must be provided. Alternatively, the corresponding shorthands -l, -o, and -m can be used respectively.\n$ deps get sources -l go -o github.com -m depscloud/api {\u0026#34;source\u0026#34;:{\u0026#34;url\u0026#34;:\u0026#34;https://github.com/depscloud/api.git\u0026#34;},\u0026#34;manages\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;system\u0026#34;:\u0026#34;vgo\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;latest\u0026#34;}} Dependents Dependent modules are those who consume the module you\u0026rsquo;re querying for. That is, modules who list your module as a dependency.\n$ deps get dependents -l go -o github.com -m depscloud/api {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.1.0\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/gateway\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.1.0\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/tracker\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.1.0\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/indexer\u0026#34;}} Dependencies Dependencies are the modules that your module requires. This should rarely differ from the modules you list in your appropriate manifest file (package.json, go.mod, etc.)\n$ deps get dependencies -l go -o github.com -m depscloud/api {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v1.3.0\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;gogo/protobuf\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.3.2\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;indirect\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/text\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.0.0-20190628185345-da137c7871d7\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;indirect\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/net\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v1.3.2\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;golang/protobuf\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.0.0-20190916214212-f660b8655731\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;google.golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;genproto\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v0.0.0-20190626221950-04f50cda93cb\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;indirect\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/sys\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v1.11.2\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;grpc-ecosystem/grpc-gateway\u0026#34;}} {\u0026#34;depends\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;version_constraint\u0026#34;:\u0026#34;v1.23.1\u0026#34;,\u0026#34;scopes\u0026#34;:[\u0026#34;direct\u0026#34;]},\u0026#34;module\u0026#34;:{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;google.golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;grpc\u0026#34;}} Topology Topologies are one of the most useful elements of a dependency graph. They can provide you with the full set of transitive modules, build orders, and notions of parallelism. While the tracker API calls out to a TopologyService, this has only been implemented as a client side feature.\nThis is largely because topological queries can be resource intensive. This is due to the fact that the subgraph needs to be buffered before any results can be returned. By implementing this as a client-side feature, we defer the memory/disk cost to clients, allowing them to buffer as they see fit while allowing the tracker to be light weight.\nTopologies can be queried in both the dependencies and dependents direction.\n$ deps get dependencies topology -l go -o github.com -m depscloud/api {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/api\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;gogo/protobuf\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/text\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/net\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;golang/protobuf\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;google.golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;genproto\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;x/sys\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;grpc-ecosystem/grpc-gateway\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;google.golang.org\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;grpc\u0026#34;} $ deps get dependents topology -l go -o github.com -m depscloud/api {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/api\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/gateway\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/cli\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/tracker\u0026#34;} {\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/indexer\u0026#34;} By adding the --tiered flag, you will get a structured set of results back. This is great for building automation around your source code as it not only identifies the order in which things should be built, but it also provides tiers where parallel builds can occur. Consider the following simple example.\n$ deps get dependents topology -l go -o github.com -m depscloud/api --tiered [{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/api\u0026#34;}] [{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/gateway\u0026#34;},{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/cli\u0026#34;},{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/tracker\u0026#34;},{\u0026#34;language\u0026#34;:\u0026#34;go\u0026#34;,\u0026#34;organization\u0026#34;:\u0026#34;github.com\u0026#34;,\u0026#34;module\u0026#34;:\u0026#34;depscloud/indexer\u0026#34;}] In this case, we only have two tiers. Each tier contains a list of modules that can be built in parallel. When one tier is complete, the next tier can be processed safely without worrying about transitive dependency issues.\n","excerpt":"Repository: https://github.com/depscloud/cli Runtime: Golang Language: Golang  Background Prior to …","ref":"/docs/cli/","title":"Command Line"},{"body":" Repository: https://github.com/depscloud/extractor Runtime: NodeJS Language: TypeScript  Background The extractor is a NodeJS process written in TypeScript. This was an intentional design decision when it came to writing this part of the system. In previous implementations, attempting to work with manifest files in a strongly typed language proved to be rather tedious. As a result, it inspired the use of a more scientific language where there is more flexibility around the data types we\u0026rsquo;re working with. While both JavaScript and Python afforded the flexibility I was looking for in a system, it was Typescript that offered the best of both worlds.\nContributing an extractor This is by far, one of the easiest ways to contribute to the project. It involves adding a new class to the code base under the src/extractors directory. Once you\u0026rsquo;ve added the new extractor, you can register it using the ExtractorRegistry. The following code snippet illustrates the bare elements needed to write a custom extractor.\nexport default class FileExtractor implements Extractor { public requires(): string[] { return [ \u0026#34;my-file.ext\u0026#34; ]; } public async extract(_: string, files: { [p: string]: ExtractorFile }): Promise\u0026lt;DependencyManagementFile\u0026gt; { const { ... } = files[\u0026#34;my-file.ext\u0026#34;].json(); const allDependencies = []; return { language: Languages.NODE, system: \u0026#34;my-system\u0026#34;, organization, module, version, dependencies: allDependencies, }; } } Swagger Explorer By leveraging the grpc-gateway project, we\u0026rsquo;re able to easily generate Swagger documentation for the API. This allows you to leverage the Swagger UI to easily browse the API and it\u0026rsquo;s operations. For convenience, this has been embedded below.\n\t window.onload = function() { const ui = SwaggerUIBundle({ url: \"https://api.deps.cloud/swagger/v1alpha/extractor/extractor.swagger.json\", dom_id: '#ohpen_swagger_ui', presets: [ SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset ] }) window.ui = ui } \t","excerpt":"Repository: https://github.com/depscloud/extractor Runtime: NodeJS Language: TypeScript  Background …","ref":"/docs/services/extractor/","title":"Extractor"},{"body":"In order to start developing using Docker, first deploy the stack using the directions . You can deploy the stack using either SQLite or MySQL as a backend data store.\nBuilding Local Changes To help facilitate contributions, each project has a docker target that builds the project inside a container.\n   Project Managed by docker Target     Golang Makefile make docker   NodeJS package.json npm run docker    The target produces a tagged image that you can deployed using the existing docker example.\nDeploying Local Changes Once you\u0026rsquo;ve produced an image containing your local changes, you can easily update your stack to pick up the new image.\n$ docker-compose up -d ","excerpt":"In order to start developing using Docker, first deploy the stack using the directions . You can …","ref":"/docs/contributing/docker/","title":"Developing in Docker"},{"body":"Local targets are available for development. In order to leverage those targets, you will need to install the appropriate tooling. While most projects are written in Golang, there are a few that will require NodeJS or Ruby. To help simplify some of the setup, I\u0026rsquo;ve included a general guide to managing these versions locally.\nGolang Install and manage Golang versions using gvm.\n$ bash \u0026lt; \u0026lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) $ source ${HOME}/.gvm/scripts/gvm Once installation is complete, you should be able to install and use specific versions of Golang.\n$ gvm install go1.12.4 $ gvm alias create default go1.12.4 $ gvm use default $ go version go version go1.12.4 darwin/amd64 $ which go ${HOME}/.gvm/gos/go1.12.4/bin/go NodeJS Install and manage NodeJS versions using nvm.\n$ curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash Once installation is complete, you\u0026rsquo;ll need to restart your shell to pick up the new environment variables. Then, you should be able to install and use specific versions of NodeJS.\n$ nvm install 10.15.3 $ nvm alias default v10.15.3 # all new shells will use 10.15.3 $ nvm use default # changes node version for the current terminal $ nvm current # verify you're using the right version v10.15.3 $ which node ${HOME}/.nvm/versions/node/v10.15.3/bin/node Ruby Install and manage Ruby versions using rvm.\n## OSX $ brew install gpg2 $ gpg --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB ## Linux $ gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB $ curl -sSL https://get.rvm.io | bash -s stable Once installation is complete, you\u0026rsquo;ll need to restart your shell to pick up the new environment variables. Then, you should be able to install and use specific versions of Ruby.\n$ rvm install 2.3.7 $ rvm alias create default 2.3.7 $ rvm use default $ rvm current ruby-2.3.7 $ which ruby ${HOME}/.rvm/rubies/ruby-2.3.7/bin/ruby ","excerpt":"Local targets are available for development. In order to leverage those targets, you will need to …","ref":"/docs/contributing/local/","title":"Developing Locally"},{"body":"All projects are open to contributions. Be sure to consult all the resources below prior to contributing.\nProcess and Project Management The deps.cloud project leverages a public GitHub Project for tracking its work items. For new comers, there\u0026rsquo;s a section that provides some detail around how to get started developing on the project.\nContributor Agreements To help protect the project owners and contributors to the project, we\u0026rsquo;ve established a common set of CLAs. The Individual Contributor Agreement should be signed by anyone who submits code to the project. The Corporate Contributor Agreement should be signed by any organization whose engineers are submitting code on their behalf.\nIndividual Contributors For the individual contributor agreement, we leverage cla-assistant.io. A copy of this agreement can be found here. This agreement will need to be signed by anyone looking to contribute code to the project. To sign this agreement, you can go here and sign using your github account:\nhttps://cla-assistant.io/depscloud/deps.cloud\nCorporate Contributors If you are submitting code on behalf of your company, please ensure your company has submit a copy of our Corporate Contributor Agreement. You can find a copy of the corporate agreement here. When complete, you can email a copy of it to us.\n","excerpt":"All projects are open to contributions. Be sure to consult all the resources below prior to …","ref":"/docs/contributing/","title":"Contributing"},{"body":"The term \u0026lsquo;master\u0026rsquo; is used heavily across the technical community. It\u0026rsquo;s used to represent primary instances in a database, branches in repositories, and so much more. But this term is also associated with racism, oppression, violence, and hate.\nTo help show our support for the black community, the default branch has been renamed to main. While this is one small change in one project, we hope that many others follow suit.\nIf you are contemplating making a similar change, it was easy to do with some shell scripting. The deps.cloud projects took about 30 minutes to migrate, including content auditing. You can follow along with the snippet below as it was used to move the deps.cloud ecosystem. While this script is specific to GitHub, it should be easy to modify for other systems.\n# setup credentials for the api export GITHUB_AUTHORIZATION=\u0026#34;token OAUTH-TOKEN\u0026#34; export GITHUB_GROUP=\u0026#34;depscloud\u0026#34; export BRANCH_NAME=\u0026#34;main\u0026#34; # start with a fresh copy of your code (just to be safe) curl -sSL -H \u0026#34;Authorization: ${GITHUB_AUTHORIZATION}\u0026#34; https://api.github.com/users/${GITHUB_GROUP}/repos | \\  jq -r .[].ssh_url | \\  xargs -I{} git clone {} # checkout a new branch and push it find . -maxdepth 2 -name .git | \\  xargs dirname | \\  xargs -I{} git --git-dir={}/.git --work-tree={} checkout -b ${BRANCH_NAME} find . -maxdepth 2 -name .git | \\  xargs dirname | \\  xargs -I{} git --git-dir={}/.git --work-tree={} push -u origin ${BRANCH_NAME} # update the default branch find . -maxdepth 2 -name .git | \\  xargs dirname | \\  xargs basename -a | \\  xargs -I{} echo https://api.github.com/repos/${GITHUB_GROUP}/{} | \\  xargs -I{} curl \\  -X PATCH \\  -H \u0026#34;Content-Type: application/json\u0026#34; \\  -H \u0026#34;Authorization: ${GITHUB_AUTHORIZATION}\u0026#34; \\  -d \u0026#34;{\\\u0026#34;default_branch\\\u0026#34;: \\\u0026#34;${BRANCH_NAME}\\\u0026#34;}\u0026#34; {} ## ## Congratulations! ## ## You\u0026#39;ve gotten to the point where active development should no longer be against master. ## Now, you don\u0026#39;t want to go and delete it quite yet as you might have some external links pointing to the branch. ## You\u0026#39;ll want to make sure you do an audit of your projects content, badges, and workflows. ## Once you\u0026#39;ve verified all the references have been updated, you\u0026#39;ll be able to proceed on. ## ## Notes: ## * Some system may require making some additional changes (like setting up protected branches). ## # delete the master branch find . -maxdepth 2 -name .git | \\  xargs dirname | \\  xargs -I{} git --git-dir={}/.git --work-tree={} push origin :master ","excerpt":"The term \u0026lsquo;master\u0026rsquo; is used heavily across the technical community. It\u0026rsquo;s used to …","ref":"/blog/2020/06/13/new-default-branch-main/","title":"New Default Branch: main"},{"body":"deps.cloud is composed of several independent services working together. This section contains some technical documentation about each one.\n","excerpt":"deps.cloud is composed of several independent services working together. This section contains some …","ref":"/docs/services/","title":"API Services"},{"body":"","excerpt":"","ref":"/blog/","title":"Blog"},{"body":"        Track, monitor, and connect project dependencies across different languages and toolchains.                                Learn More  Supported Manifests        ","excerpt":"        Track, monitor, and connect project dependencies across different languages and toolchains. …","ref":"/","title":"deps.cloud"},{"body":"","excerpt":"","ref":"/docs/","title":"Documentation"},{"body":"Welcome to the deps.cloud blog! It will be an easy way to stay on top of the latest news, release notes, and updates from the community. Since the project is composed of several pieces, it can be hard to track progress across all of them. This enables the presentation of cross cutting features and larger changes to the ecosystem.\nContributors and consumers are encouraged to generate content for the blog. For contributors, it\u0026rsquo;s a great way to showcase a feature you\u0026rsquo;ve contributed to the project. For consumers, it\u0026rsquo;s an opportunity to discuss how it\u0026rsquo;s been able to help benefit your ecosystems.\nWe look forward to your contributions!\n","excerpt":"Welcome to the deps.cloud blog! It will be an easy way to stay on top of the latest news, release …","ref":"/blog/2020/06/06/introducing-the-deps.cloud-blog/","title":"Introducing the deps.cloud blog"},{"body":"","excerpt":"","ref":"/search/","title":"Search Results"}]